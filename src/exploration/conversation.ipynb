{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRasmusBm/chatbot-epsilon/blob/master/src/exploration/conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWjzaSJz2rZp",
        "colab_type": "text"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xZh6wQA2vGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXm_r12d2wCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"amazon_cells_labelled.txt\"\n",
        "uploaded[file_name].decode(\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIhLVvpw3HiD",
        "colab_type": "text"
      },
      "source": [
        "#Import code (from TA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAbfYsRd3VaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKF-Qfr63DG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_pandas(data, columns):\n",
        "    df_ = pd.DataFrame(columns=columns)\n",
        "    data['Sentence'] = data['Sentence'].str.lower()\n",
        "    data['Sentence'] = data['Sentence'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n",
        "    data['Sentence'] = data['Sentence'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n",
        "    data['Sentence'] = data['Sentence'].str.replace('[^\\w\\s]','')                                                       # remove special characters\n",
        "    data['Sentence'] = data['Sentence'].replace('\\d', '', regex=True)                                                   # remove numbers\n",
        "    for index, row in data.iterrows():\n",
        "        word_tokens = word_tokenize(row['Sentence'])\n",
        "        filtered_sent = [w for w in word_tokens if not w in stopwords.words('english')]\n",
        "        df_ = df_.append({\n",
        "            \"index\": row['index'],\n",
        "            \"Class\": row['Class'],\n",
        "            \"Sentence\": \" \".join(filtered_sent[0:])\n",
        "        }, ignore_index=True)\n",
        "    return data\n",
        "\n",
        "# If this is the primary file that is executed (ie not an import of another file)\n",
        "if __name__ == \"__main__\":\n",
        "    # get data, pre-process and split\n",
        "    data = pd.read_csv(\"amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
        "    data.columns = ['Sentence', 'Class']\n",
        "    data['index'] = data.index                                          # add new column index\n",
        "    columns = ['index', 'Class', 'Sentence']\n",
        "    data = preprocess_pandas(data, columns)                             # pre-process\n",
        "    training_data, validation_data, training_labels, validation_labels = train_test_split( # split the data into training, validation, and test splits\n",
        "        data['Sentence'].values.astype('U'),\n",
        "        data['Class'].values.astype('int32'),\n",
        "        test_size=0.10,\n",
        "        random_state=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # vectorize data using TFIDF and transform for PyTorch for scalability\n",
        "    word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=50000, max_df=0.5, use_idf=True, norm='l2')\n",
        "    training_data = word_vectorizer.fit_transform(training_data)        # transform texts to sparse matrix\n",
        "    training_data = training_data.todense()                             # convert to dense matrix for Pytorch\n",
        "    vocab_size = len(word_vectorizer.vocabulary_)\n",
        "    validation_data = word_vectorizer.transform(validation_data)\n",
        "    validation_data = validation_data.todense()\n",
        "    train_x_tensor = torch.from_numpy(np.array(training_data)).type(torch.FloatTensor)\n",
        "    train_y_tensor = torch.from_numpy(np.array(training_labels)).long()\n",
        "    validation_x_tensor = torch.from_numpy(np.array(validation_data)).type(torch.FloatTensor)\n",
        "    validation_y_tensor = torch.from_numpy(np.array(validation_labels)).long()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhYlj6cM5YQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vVo7lvEpY8",
        "colab_type": "text"
      },
      "source": [
        "#Smal init from: From Zero to Hero with PyTorch\n",
        "[link here](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxN8VE_VEriW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 5\n",
        "hidden_dim = 20\n",
        "n_layers = 2\n",
        "\n",
        "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjXtqFrFYBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2\n",
        "seq_len = 1\n",
        "\n",
        "inp = torch.randn(batch_size, seq_len, input_dim)\n",
        "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "hidden = (hidden_state, cell_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SoJgbkkFY2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out, hidden = lstm_layer(inp, hidden)\n",
        "print(\"Output shape: \", out.shape)\n",
        "print(\"Hidden: \", hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqhATguxFjaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(out[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHON4jnNGrlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHFAxt10IeTT",
        "colab_type": "text"
      },
      "source": [
        "#SEQUENCE MODELS AND LONG-SHORT TERM MEMORY NETWORKS\n",
        "[link here](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_N--6TNI_J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "training_data = [\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "word_to_ix = {}\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "print(word_to_ix)\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "\n",
        "# These will usually be more like 32 or 64 dimensional.\n",
        "# We will keep them small, so we can see how the weights change as we train.\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3-o-lTTIfhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dim-RcXJDgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# See what the scores are before training\n",
        "# Note that element i,j of the output is the score for tag j for word i.\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "    print(tag_scores)\n",
        "\n",
        "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in training_data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "        # Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        #  calling optimizer.step()\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# See what the scores are after training\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    inputs = torch.cat((inputs,  torch.tensor(np.array([8]))), 0)\n",
        "    tag_scores = model(inputs)\n",
        "\n",
        "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
        "    # for word i. The predicted tag is the maximum scoring tag.\n",
        "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
        "    # since 0 is index of the maximum value of row 1,\n",
        "    # 1 is the index of maximum value of row 2, etc.\n",
        "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
        "    print(\"inp\", inputs)\n",
        "    print(tag_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNg-HSJjJICQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}