{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/JRasmusBm/chatbot-\n",
    "epsilon/blob/master/Trainer.ipynb\" target=\"_parent\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In\n",
    "Colab\"/></a>\n",
    "\n",
    "# This is the file in which we perform training of the NN\n",
    "\n",
    "# Load\n",
    "Data\n",
    "\n",
    "## In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "63"
    }
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#file_name = \"amazon_cells_labelled.txt\"\n",
    "#uploaded[file_name].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "64"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = \"../../data\"\n",
    "training_models_folder = \"../../trained_models\"\n",
    "file_name = f\"{data_folder}/amazon_cells_labelled.txt\"\n",
    "json_file = f\"{data_folder}/amazon_cells_labelled.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import code (from TA)\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "83"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data\n",
    "\n",
    "First, we create lists of labels and sentences. The indices in\n",
    "the one\n",
    "correspond to those in the other. Due to restrictions in torchtext,\n",
    "write it as\n",
    "json to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "66"
    }
   },
   "outputs": [],
   "source": [
    "# with open(file_name) as f:\n",
    "#     contents = f.read()\n",
    "# labels = []\n",
    "# sentences = []\n",
    "# for line in (l for l in contents.split(\"\\n\") if l):\n",
    "#     labels.append(int(line[-1]))\n",
    "#     sentence = str.strip(line[:-1])\n",
    "#     while len(sentence.split(\" \")) < 5:\n",
    "#         sentence += \" a\"\n",
    "#     sentences.append(sentence)\n",
    "# data_json = [\n",
    "#     dict(label=label, text=text) for label, text in zip(labels, sentences)\n",
    "# ]\n",
    "# with open(json_file, \"w\") as f:\n",
    "    #text = \"\\n\".join(json.dumps(line) for line in data_json)\n",
    "    #f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "67"
    }
   },
   "outputs": [],
   "source": [
    "# with open(json_file) as f:\n",
    "#     json_written = [json.loads(line) for line in f.read().split(\"\\n\")]\n",
    "#     for line in json_written:\n",
    "#         if line[\"label\"] not in [0, 1]:\n",
    "#             print(line)\n",
    "#         if len(line[\"text\"].split(\" \")) < 5:\n",
    "#             print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Torchtext Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(\" \".join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "68"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize=\"spacy\", batch_first=True,)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "# fields = dict(text=(\"text\", TEXT), label=(\"label\", LABEL),)\n",
    "\n",
    "# dataset = data.TabularDataset(path=json_file, format=\"json\", fields=fields,)\n",
    "# help(dataset)\n",
    "# training_data, test_data, validation_data = dataset.split(\n",
    "#    split_ratio=[0.7, 0.2, 0.1], random_state=random.seed(SEED)\n",
    "# )\n",
    "training_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "training_data, validation_data = training_data.split(\n",
    "    random_state=random.seed(SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "69"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length (Training Data): 17500\n",
      "Length (Test Data): 25000\n",
      "Length (Validation Data): 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length (Training Data): {len(training_data)}\")\n",
    "print(f\"Length (Test Data): {len(test_data)}\")\n",
    "print(f\"Length (Validation Data): {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "70"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [19:30, 737kB/s]                                \n",
      "100%|█████████▉| 398913/400000 [00:20<00:00, 19535.56it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(\n",
    "  training_data,\n",
    "  vectors=\"glove.6B.100d\",\n",
    "  unk_init=torch.Tensor.normal_,\n",
    "  max_size = MAX_VOCAB_SIZE\n",
    ")\n",
    "LABEL.build_vocab(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "71"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n",
      "[('the', 202487), (',', 191683), ('.', 165574), ('a', 109268), ('and', 109089), ('of', 100651), ('to', 93681), ('is', 75914), ('in', 61378), ('I', 54276)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "75"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "training_iterator, validation_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (training_data, validation_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "77"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        n_filters,\n",
    "        filter_sizes,\n",
    "        output_dim,\n",
    "        dropout,\n",
    "        pad_idx,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=pad_idx\n",
    "        )\n",
    "        self.conv_0 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=n_filters,\n",
    "            kernel_size=(filter_sizes[0], embedding_dim),\n",
    "        )\n",
    "        self.conv_1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=n_filters,\n",
    "            kernel_size=(filter_sizes[1], embedding_dim),\n",
    "        )\n",
    "        self.conv_2 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=n_filters,\n",
    "            kernel_size=(filter_sizes[2], embedding_dim),\n",
    "        )\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved_0 = nn.functional.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = nn.functional.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = nn.functional.relu(self.conv_2(embedded).squeeze(3))\n",
    "        pooled_0 = nn.functional.max_pool1d(\n",
    "            conved_0, conved_0.shape[2]\n",
    "        ).squeeze(2)\n",
    "        pooled_1 = nn.functional.max_pool1d(\n",
    "            conved_1, conved_1.shape[2]\n",
    "        ).squeeze(2)\n",
    "        pooled_2 = nn.functional.max_pool1d(\n",
    "            conved_2, conved_2.shape[2]\n",
    "        ).squeeze(2)\n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "78"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PADDING_INDEX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(\n",
    "    INPUT_DIM,\n",
    "    EMBEDDING_DIM,\n",
    "    N_FILTERS,\n",
    "    FILTER_SIZES,\n",
    "    OUTPUT_DIM,\n",
    "    DROPOUT,\n",
    "    PADDING_INDEX,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "79"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,620,801 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1263,  0.1299,  0.7107,  ...,  0.2647, -0.7851,  0.2955],\n",
       "        [-0.1709,  0.3923, -0.1879,  ...,  0.9795,  0.5425,  1.5589],\n",
       "        [ 0.2429, -0.0744,  0.1650,  ...,  0.6570,  0.1391, -0.2840]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_INDEX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNKNOWN_INDEX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PADDING_INDEX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "81"
    }
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "80"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "82"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "84"
    }
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 3m 7s\n",
      "\ttraining Loss: 0.315 | training Acc: 86.68%\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 85.28%\n",
      "Epoch: 02 | Epoch Time: 3m 9s\n",
      "\ttraining Loss: 0.232 | training Acc: 90.78%\n",
      "\t Val. Loss: 0.339 |  Val. Acc: 85.99%\n",
      "Epoch: 03 | Epoch Time: 3m 10s\n",
      "\ttraining Loss: 0.164 | training Acc: 93.89%\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 87.52%\n",
      "Epoch: 04 | Epoch Time: 3m 9s\n",
      "\ttraining Loss: 0.112 | training Acc: 96.08%\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 87.23%\n",
      "Epoch: 05 | Epoch Time: 3m 7s\n",
      "\ttraining Loss: 0.076 | training Acc: 97.49%\n",
      "\t Val. Loss: 0.378 |  Val. Acc: 86.67%\n",
      "Epoch: 06 | Epoch Time: 3m 8s\n",
      "\ttraining Loss: 0.055 | training Acc: 98.24%\n",
      "\t Val. Loss: 0.415 |  Val. Acc: 86.82%\n",
      "Epoch: 07 | Epoch Time: 3m 13s\n",
      "\ttraining Loss: 0.038 | training Acc: 98.97%\n",
      "\t Val. Loss: 0.445 |  Val. Acc: 86.92%\n",
      "Epoch: 08 | Epoch Time: 2m 39s\n",
      "\ttraining Loss: 0.029 | training Acc: 99.13%\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 86.94%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "times_best_found = 0\n",
    "limit = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    training_loss, training_acc = train(model, training_iterator, optimizer, criterion)\n",
    "    validation_loss, validation_acc = evaluate(model, validation_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    training_losses.append(training_loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if validation_loss < best_validation_loss:\n",
    "        times_best_found = 0\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(model.state_dict(), f'{training_models_folder}/cnn_20_epochs_imdb.pt')\n",
    "    else:\n",
    "        print(\"NOT THE BEST\")\n",
    "        times_best_found += 1\n",
    "    if limit <= times_best_found:\n",
    "        break\n",
    "    print(f\"Stopping in {limit - times_best_found}\")\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\ttraining Loss: {training_loss:.3f} | training Acc: {training_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {validation_loss:.3f} |  Val. Acc: {validation_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f117abb2a50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(validation_losses, color=\"blue\")\n",
    "plt.plot(training_losses, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
